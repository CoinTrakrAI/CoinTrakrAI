
# Triton server configurations go here for model batching and async inference
def triton_ready():
    return True  # placeholder
